<!DOCTYPE html>
<html lang="en">
`
<head>
    <meta charset="utf-8" />
    <title>Client-Edge-Cloud coordination Use Cases and Requirements</title>

    <style>
    .two-cols {
      display: grid;
      grid-template-columns: 1fr 1fr;
    }

    table {
      border-collapse:collapse;
    }

    table,th, td {
      border: 1px solid #666;
    }

    td {
      padding:2px 15px;
    }
    </style>

    <script async class="remove" src="https://www.w3.org/Tools/respec/respec-w3c"></script>

    <script class="remove">
        var respecConfig = {
            specStatus: "ED",
            previousPublishDate: "2021-05-31",
            previousMaturity: "draft",
            copyrightStart: "2021",
            edDraftURI: "",

            shortName: "client-edge",
            noRecTrack: true,
            copyrightStart: "2021",

            editors: [{
                name: "Dapeng(Max) Liu",
                companyURL: "http://www.alibabagroup.com/en/global/home",
                company: "Alibaba Group"
              },

              {
                name: "Feiwei Lei",
                companyURL: "http://www.alibabagroup.com/en/global/home",
                company:"Alibaba Group"
              },

              {
                name: "Jingyu Yang",
                companyURL: "http://www.alibabagroup.com/en/global/home",
                company:"Alibaba Group"
              }
            
            ],

            group: "",
            wgPublicList: "",

        };
    </script>
</head>

<body>
    <section id='abstract'>
        <p>
        This document introduces the use cases and requriments of client, edge, cloud coordination mechanism and its standardization. 
        </p>
    </section>
    <section id='sotd'>
        <p>
        This is still a work in progress. The proposal is being incubated in the <a href="https://github.com/w3c/web-networks/">W3C Web & Networks Interest Group</a>.
        </p>
    </section>

    <section>
      <h2>Introduction</h2>
        <p>With the rapid development of cloud computing technology, the centralized cloud is evolving towards distributed "edge cloud" that allows developers to deploy their code as FaaS in 
          the edge cloud which is close to the user's location. One of such service is Alibaba Cloud's <a href="https://help.aliyun.com/document_detail/154621.html?spm=5176.14063831.J_5235666150.3.2cf97427yw6WJ6/">EdgeRoutine</a> 
          service.</p>
      
        <p>
          With the rapid adoption of new technologies such as machine learning, IoT ect in the client side's applications, the client side's application may also need to perform computing intensive work. For example, machine
          learning inference can also be done in client side. As one of such examples, Taobao mobile App leverages client side machine learning inference for user face detection etc. 
          W3C is also working on <a href="https://www.w3.org/groups/wg/webmachinelearning">WebNN</a>  standard that allow client side developers to leverage the machine learning acceleration 
          hardwares that resides in the client side devices.
        </p>

        <p>
          To improve the client side application's performance, there is a trend to offload computing intensive work to the edge cloud, such as cloud app, cloud gaming etc.
          However, current approch could be further optimized if there is a mechanism for Client-Edge-Cloud coordination.
          This document discusses the use cases and requriments of Client-Edge-Cloud coordination mechanism and its standardization.
        </p>

        <p>
          
        </p>

    </section>

    <section>
      <h2>Use Cases</h2>
      <p>
        The client side application could be generally classified into the following categories:
      </p>
        <li>Render intensive application</li>
          <p>
            Render intensive application refers to the client side applications whose main task is to fetch the content from the backend server then rendering the content in the front-end.
            For example, news,social media Web applications and mobile applications belongs to this category.
          </p>
        <li>Computing intensive application</li>
          <p>
            Computing intensive application refers to the client side applications whose main task is to do computing intensive work in the client side. For example, mobile gaming applications 
            need to calculate certain object's location and other complex parameters based on user interaction then rendering in the client side. 
          </p>
        <li>Hybrid application</li>
          <p>
            Hybrid application refers to the application whose main task includes both rendering intesive work and computing intensive work. For example, morden e-commerce mobile application 
            leverage machine learning inference in the client side for AR tpye user experience. At the same time, the e-commerce mobile application needs to fetch dynamic content based
            on uesr preference.
          </p>
        <li>Mobile/static client</li>
        <p>
          Some client side applications remain static most of the time. For example, a camera for traffic monitorning and analysis do not require mobility support. 
          On the other hands, some client side application will change its location continuously. For example, for applications running on a connected vehicle or self driving vehicle, 
          it will change its location rapidly with the vehicle.
        </p>

       

        <section>
          <h3>Cloud App</h3>
          <p>
            Cloud App is a new form of AIoT application which utilizing cloud computing technology to move native mobile application to the cloud. The user interaction happens 
            in the client device side and the computing and rendering process happens in the edge cloud side. This can lower the client's hardware requirement and reduce
            the cost.
          </p>

          <p>
            As one examples of cloud App, Alibaba's Tmall Genie smart speaker leverage edge cloud to offload the computing intensive work from the client side to the edge cloud.
          </p> 

          <p>
            The client, the central cloud, the edge cloud works together in a coordinated way for Cloud App. Typically, the control and orchestration function is located in the central cloud.
            The computing intensive function is located in edge cloud. The user intercation and display function is located in the client.
          </p>

          <figure>
            <img alt="CloudApp" src="images/CloudApp.png" width="600">
            <figcaption>
              Cloud App Architecture
            </figcaption>
          </figure>

        </section>

        <section>
          <h3>Connected vehicles/Self-driving</h3>
          <p>
            Connected vehicles/self-driving cars normally have applictions running on the vehicles. For example, the applications may include Apps for entertainment, navigation ect or for 
            functionalities. Similar with cloud app use cases, some of those applications can be offloaded to the edge cloud. Due to the mobility of the vehicles, other factors, such as the 
            stability of network connection need to be considered when offloading. 
          </p>

        </section>


        <section>
          <h3>VR/AR</h3>
          <p>
            VR/AR devices such as VR/AR glasses normally has limited hardware resources, so it is preferred to offload the computing intensive task to the edge for acceleration and
            reducing delay since the edge server is deployed near the location of the user.
          </p>
	  <p>
	  Note: this could be generalized to "low-latency tasks".  Some other examples might include 
	  game physics simulation or CAD tools (in a business environment).  The latter might add confidentiality
	  constraints (a business user may want to offload to on-premises computers).
	  We may also want to clarify that this pattern is for local communication to/from the client.
	  See also "Streaming Acceleration", where the communication is in-line with an existing network
	  connection.
	  </p>
        </section>


        <section>
          <h3>Machine learning </h3>
          <p>
            Machine larning inference can be done in the client side to reduce latency. W3C is working on <a href="https://www.w3.org/groups/wg/webmachinelearning">WebNN</a>  standard that 
            allows client side developers to leverage the machine learning acceleration hardwares reside in the client side devices.
          </p>

          <p>
            However, since the edge cloud is located near to the client and have more powerfull hardware resources, it is also possbile to offload the machine learning inference task to the edge.
          </p>
        </section>


        <section>
          <h3>High availability application</h3>

          <p>
            For the applications which offload some parts of its functionalities to the edge cloud, if the edge cloud is not available due to UE mobility or other reasons,
            it is preferred that the functionalities could be handed over back to the client. More complex rules could be designed to improve the robustness of the application.
          </p>
        </section>

        <section>
          <h3>Online Video Conference</h3>
          <p>
            For online video conference application, the online video conference system provides realtime translation and subtitles service. This will use AI technology and it is
            computing intensive. Also, the real time translation service is very delay sensitive. 
          </p>
          <p>
            The online video conference application could be installed on PC terminals or mobile terminals.
            For PC terminals, there is enough computing resources and enough disk storage to allow the installation of online video conference application. In this case, the computing
            intensive work could be done in the PC terminal and providing ultra-low latency user experience.
          </p>

          <p>
            For mobile terminals, there is limited disk storage and limited computing capability, it is not possbile to run the computing intensive task on the mobile terminals. In this case,
            the computing intensive task could be offloaded to the edge and then providing ultra-low latency user experience.
          </p>

          <p>
            It is preferred that in this use case the online video conference application can offload the computing intensive task according to the terminal capability and edge resources availability.
            The online video conference service provider can provide consistent user experience on different terminals.
          </p>
        </section>

        <section>
          <h3>Image Processing</h3>
          <p>
            For some mobile image processing applications, it is required to use AI algorithm for the image analysis and processing. It is normally need NPU chipset on the terminals for better performance.
            For the terminals that without NPU chipset, it is preferred to offload the AI computing intensive task to the edge and this will provide a consistent user experience on different terminals.
          </p>
        </section>

        <section>
          <h3>Automatic License Plate Recognition</h3>
          <p>
            For automatic license plate recognition applications, offline processing can provide 90% recognition rate. Online processing on the edge will improve the recognition rate to 99%. 
            It is preferred to offload the license plate recognition computing intensive task to edge when the network connection is stable and if the network condition is not stable or broken, the offloaded computing
            intensive task could move back to the terminals to guarantee the availability of the service.
          </p>
        </section>
    
      <section>
          <h3>Persistent tasks</h3>
          <p>
	  In some cases it may be desireable to a task from a browser that continues to run even when the 
	  browser application is not active.  This could be used to monitor a condition for example and send
	  a notification when that condition is met.  As a sub-category of this use case, the offloaded task
	  might be used to monitor IoT devices and instead of or in addition to sending a notification, it
	  might be used for automation. 
	  Such an offloaded task might also be used to execute long-running computational
	  tasks such as machine learning or data indexing.
          </p>
	  <p>
	  Persistent tasks require a mechanism to manage their lifetime using expiry dates or explicit controls.
	  In the case of applying this to IoT orchestration, there is also the issue of granting access rights
	  to such offloaded tasks, for example access to a LAN, to specific IoT devices on that LAN, and to the 
	  data they generate.
	  </p>
        </section>

        <section>
          <h3>Streaming Acceleration</h3>

          <p>In the case of video acceleration, we may want to offload work to a location with both
	  compute performance that is already on the network path.  Specifically, consider a low-performance
	  client that wants to compress video or do background removal as part of a teleconference.
	  It could connect over a local high-performance wireless network to a local edge computer (perhaps
	  an enhanced ISP gateway box) that would then perform the video processing and forward the processed
	  video to the network.
	  </p>
	  <p>
	  We may also want to clarify that this pattern is for communication  in-line with an existing
	  network.
	  See also "VR/AR" (should be generalized), where the communication is to/from the offload target.
	</section>

	<section>
	  <h3>Robot Navigation Acceleration</h3>
	  <p>
	  Consider a robot navigating in a home using Visual SLAM.  In this case the robot has limited
	  performance due to cost and power constraints.  So it wishes to offload the video processing work
	  to another computer.  However, the video is sensitive private data so the user would prefer that
	  it does not leave the user's premises, and would like to offload the processing to an existing
	  desktop computer or an enhanced gateway.  Latency may also be a concern (the robot needs the 
	  results immediately to make navigation decisions, for example to avoid a wire or other obstacle
	  on the floor).
	  </p>
	  <p>
	  Note: in general, there are other opportunities for IoT devices to want to offload work to another
	  computer.  Video processing however is of special interest because of its high data and processing
	  requirements and privacy constraints.
	  </p>
	</section>
        

    <section>
      <h2>Gap Analysis</h2>
    </section>
    <section>
      <h2>Requirements</h2>
      <p>
        The requriments that was derived from the use cases are listed bellow.
      </p>

        <table>
          <tbody>
            <tr>
              <th>Requriments</th>
              <th>Related Use Cases</th>
            </tr>
            
            <tr>
              <td>R1: Client should be able to offload computing intensive work to the edge cloud. </td>
              <td>Use case 2.1, 2.2, 2.3, 2.4, 2.5; </td> 
            </tr>

            <tr>
              <td>R2: The edge cloud should be able to handover computing intensive work back to the client.</td>
              <td>Use case 2.1,2.2, 2.5;</td>
            </tr>
          
          </tbody>
        </table>
    </section>

    <section>
      <h2>Architecture Proposals</h2>
      <p>
        This document proposes different architecures that address the needs identified above.</p>

      <section>
        <h3>Seamless code sharing across client/edge/cloud</h3>
        <p>This architecture allows the client, edge and the central cloud share a common code running environment which allows the 
        task running in either client, edge, cloud or both in a coordinated way. 
      </p>

        <p>
          The proposed high level architecure is shown in the following figure:
        </p>

        <figure>
          <img alt="ClientEdgeArchitecture" src="images/Client_Edge_Architecture_v3.png" width="600">
          <figcaption>
            Proposed High Level Architecture
          </figcaption>
        </figure>
      </section>


    </section>

    <section>
          <h2>Standardization Proposals</h2>
            <section>
              <h3>WebAssembly as unified runtime</h3>
                <p> This proposal proposes to extend WebAssembly runtime and use it in both client side and edge cloud side as unified runtime.</p>
                <figure> 
                    <img src="images/WebAssemblyRuntime.png" alt="WebAssemblyRuntime" width="600">
                        <figcaption>
                          WebAssembly As Unified Runtime Architecure
                        </figcaption>
                </figure> 

                <p>
                  The proposed solution includes the following parts:
                </p>

                <li>Load wasm code</li>
                    <p>
                      The client load the WebAssembly code by invoking a standard API. This API should indicate that the wasm code could be offloaded to Edge cloud when certain condition is meet.
                      This API should also set the destination Edge cloud's location identifier.
                    </p>

                <li>Offload wasm code to Edge Cloud</li>
                    <p>
                      The client side's WebAssembly runtime excutes the wasm code and when certain condition is meet, it offload the wasm code to the Edge cloud.
                    </p>

                <li>Run wasm code on Edge cloud</li>
                    <p>
                      The wasm code runs on the Edge cloud, and return the result back to the client side.
                    </p>

                <li>Dispatch back to the client</li>
                    <p>
                      When certain condition is meet, the wasm code is dispatched back to the client side and continue to run.
                    </p>
                </section>
              
              <section>
                <h3>Potential standards</h3>
                  <li>API to load wasm code</li>
                    <p>
                      This API is used to load wasm code to the client's WebAssembly runtime, and it indicates this wasm code could be offloaded to the Edge cloud when certain condition is meet.
                      The standardization of this API is required since different WebAssembly runtime implementation should implement this API in the same way to make sure that the developers have the 
                      same user experience.
                    </p>

                  <li>Communication mechanism and protocol between client and Edge cloud WebAssembly runtime</li>
                    <p>
                      The communication mechanism, the communication protocol and the interface between the client side WebAssembly runtime and the Edge cloud side WebAssembly runtime should be standardized to enable
                      the interoperability of different WebAssembly runtime vendors.
                    </p>

                  <li>Edge cloud availability and network condition discovery</li>
                    <p>
                      The wasm code should only be offloaded when certain condition is meet. The condition may includes Edge cloud availability and network condition etc.
                      Whether this part should be standardized is TBD.
                    </p>

                  <li>Offloading policy </li>
                    <p>
                      This proposal recommend that offloading policy is not standardized to allow the flexibility implementation of different vendors. 
                    </p>
              </section>
          
    </section>

    
</body>

</html>
